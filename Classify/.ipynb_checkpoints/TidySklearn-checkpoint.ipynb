{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "from sklearn. preprocessing import label_binarize\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "from tabulate import tabulate\n",
    "from numba import njit\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import LinearSVC, SVC, NuSVC\n",
    "from sklearn.tree import DecisionTreeClassifier, ExtraTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import RadiusNeighborsClassifier, RadiusNeighborsClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier, BaggingClassifier, ExtraTreesClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier, StackingClassifier\n",
    "from sklearn.ensemble import RandomTreesEmbedding\n",
    "from sklearn.linear_model import LogisticRegression, PassiveAggressiveClassifier\n",
    "from sklearn.linear_model import Perceptron, RidgeClassifier, SGDClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "class Classify:\n",
    "    \"\"\"\n",
    "    This function assits in the classification task. It cannot do multi-label classifications.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        This sets all attributes to None. It takes no arguments.\n",
    "        \"\"\"\n",
    "        \n",
    "        self.X = None\n",
    "        self.y = None\n",
    "        \n",
    "        self.N = None\n",
    "        self.M = None\n",
    "        \n",
    "        self.C = None\n",
    "        self.L = None\n",
    "        \n",
    "        # This is where we will keep all the classifiers.\n",
    "    \n",
    "        self.fits = dict()\n",
    "        \n",
    "        # This says if data is valid. True unless shown to be false.\n",
    "        \n",
    "        self.data_valid = True\n",
    "        \n",
    "        # This is for y with more than one level.\n",
    "        \n",
    "        self.label_bins = None\n",
    "        \n",
    "        self.priors = None\n",
    "        \n",
    "        self.label = None\n",
    "        self.label_position = None\n",
    "        \n",
    "        self.folds = None\n",
    "\n",
    "        \n",
    "    ###################################################################################\n",
    "    ###################################################################################\n",
    "        \n",
    "    def data(self, X, y, level_order = None, label = None, priors = None, folds = 5):\n",
    "        \"\"\"\n",
    "        X : predictors\n",
    "        \n",
    "        y : response\n",
    "        \n",
    "        level_order : order you want the levels to be displayed. It will use \n",
    "        lexiographic (alphanumeric) order if not specified (from method .sort())\n",
    "        \n",
    "        label : the label you are interested in. 'average' is chosen if 'None' is input.\n",
    "        \n",
    "        priors : given priors. empirical if not specified.\n",
    "        \n",
    "        folds : the number of folds you wish to evaluate the data on.\n",
    "      \n",
    "        \"\"\"\n",
    "\n",
    "        self.data_valid = True\n",
    "        \n",
    "        if not isinstance(X,pd.DataFrame):\n",
    "            try:\n",
    "                X = pd.DataFrame(X)\n",
    "            except:\n",
    "                print('X must covertable to pd.DataFrame!')\n",
    "                self.data_valid = False\n",
    "                return\n",
    "    \n",
    "        if not isinstance(y, pd.Series):\n",
    "            if isinstance(y,pd.DataFrame):\n",
    "                if y.shape[1] == 1:\n",
    "                    y = pd.Series(y)\n",
    "                else:\n",
    "                    print('y must have one column!')\n",
    "                    self.data_valid = False\n",
    "                    return\n",
    "            else:\n",
    "                try:\n",
    "                    y = pd.Series(y)\n",
    "                except:\n",
    "                    print(\"y must be convertable to a pd.Series!\")\n",
    "                    self.data_valid = False\n",
    "                    return\n",
    "                    \n",
    "        if y.dtype != np.dtype('O'):\n",
    "            print('y must be of dtype Object with each element of type str!!')\n",
    "            self.data_valid = False\n",
    "            return\n",
    "    \n",
    "        # Check to make sure factors and response have the same number of rows.\n",
    "        \n",
    "        if X.shape[0] != y.shape[0]:\n",
    "            print(\"X and y must have same number of rows!\")\n",
    "            self.data_valid = False\n",
    "            return\n",
    "        \n",
    "        # Remove rows that contain None or NaN or +- inf\n",
    "        \n",
    "        remove = (~np.isfinite(X)).sum(axis=1) + y.isnull()\n",
    "        remove_sum = remove.sum()\n",
    "        if remove_sum > 0:\n",
    "            X.drop(remove,axis=0)\n",
    "            y.drop(remove)\n",
    "            print('There were ' + str(remove_sum) + ' rows removed due to missingness or inf.')\n",
    "            \n",
    "        # N is rows and M is columns\n",
    "        self.N = X.shape[0]\n",
    "        self.M = X.shape[1]\n",
    "    \n",
    "        # C is the unique categories\n",
    "        # L is the number of categories\n",
    "        \n",
    "        C = y.unique()\n",
    "        self.L = len(C)\n",
    "        \n",
    "        # make sure there are al least two levels!\n",
    "        # while is is more propery 'validation'\n",
    "        # it most naturally fits here.\n",
    "        \n",
    "        if self.L <= 1:\n",
    "            print(\"There needs to be two or more levels in y!\")\n",
    "            self.data_valid = False\n",
    "            return\n",
    "    \n",
    "        # Put in lexographical order if no order specified.\n",
    "        \n",
    "        if level_order == None:\n",
    "            C.sort()\n",
    "        elif not sum(np.sort(C) == np.sort(level_order)):\n",
    "            C = level_order\n",
    "        else:\n",
    "            print('There was a problem with level_order!')\n",
    "            self.data_valid = False\n",
    "            return\n",
    "        \n",
    "        # assign as attribute\n",
    "        \n",
    "        self.C = C\n",
    "        \n",
    "        X, y = shuffle(X,y)\n",
    "        \n",
    "        X = X.reset_index(drop=True)\n",
    "        y = y.reset_index(drop=True)\n",
    "        \n",
    "       \n",
    "        self.label_bins = label_binarize(y.values, classes=self.C)\n",
    "        \n",
    "        if self.L == 2:\n",
    "            self.label_bins = np.append(self.label_bins,1-self.label_bins,axis=1)\n",
    "        \n",
    "        self.label_bins = np.array(self.label_bins,dtype=bool)\n",
    "        \n",
    "        if label == None and self.L != 2:\n",
    "            self.label_position = self.L\n",
    "            self.label = \"Averaged\"\n",
    "        elif label == None and self.L == 2:\n",
    "            self.label_position = self.L-1\n",
    "            self.label = self.C[-1]\n",
    "        elif label in self.C:\n",
    "            self.label_position = np.where(self.C == label)[0][0]\n",
    "            self.label = label\n",
    "        else:\n",
    "            print('Label is not in y!')\n",
    "            self.data_valid = False\n",
    "            return\n",
    "        \n",
    "        if priors == None:\n",
    "            self.priors = np.append(y.value_counts(normalize=True)[self.C].values,1/self.L)\n",
    "        elif len(priors) == self.L:\n",
    "            priors = np.array(priors)\n",
    "            self.priors = priors/sum(priors)\n",
    "        else:\n",
    "            print('The length of your priors is not right!')\n",
    "            self.data_valid = False\n",
    "            return\n",
    "        \n",
    "        sc = StandardScaler()\n",
    "        X = sc.fit_transform(X)\n",
    "        X = pd.DataFrame(X)\n",
    "        \n",
    "        if folds == None:\n",
    "            self.folds = 3\n",
    "        elif 1 < folds <= self.N:\n",
    "            self.folds = folds\n",
    "        else:\n",
    "            print('Too many or two few cross validation folds!')\n",
    "            self.data_valid = False\n",
    "            \n",
    "        if self.data_valid:\n",
    "            print(\"Your data has been validated to work with sklearn.\\n\")\n",
    "            \n",
    "            self.X, self.y = X, y\n",
    "            \n",
    "        else:\n",
    "            print('Your data has has errors!')\n",
    "        \n",
    "        dims = [['N Rows',self.N],['M Columns',self.M],['levels',self.L]]\n",
    "        \n",
    "        print(tabulate(dims,headers=['Name','Value']))\n",
    "        \n",
    "        dims2 = []\n",
    "        for i in range(self.L):\n",
    "            dims2.append([self.C[i], self.priors[i]])\n",
    "        \n",
    "        print('\\n')\n",
    "        print(tabulate(dims2,headers=['Levels','Prior']),end='\\n\\n')\n",
    "        \n",
    "        \n",
    "        \n",
    "    ################################################################################\n",
    "    ################################################################################\n",
    "    \n",
    "    def add_fit(self, clf, name=None, replace=False, params = None):\n",
    "        \"\"\"\n",
    "        This will add a specific classifier.\n",
    "        \n",
    "        clf : an instance of a classifier.\n",
    "        \n",
    "        name : what you want to call it, by default it is the class name. If the name\n",
    "        already exists it will numerate them.\n",
    "        \n",
    "        replace: if the name already exists but you want to repalce it, set to True.\n",
    "        \"\"\"\n",
    "        \n",
    "        \n",
    "        if not self.data_valid:\n",
    "            print('Data is not valid!')\n",
    "            return\n",
    "        \n",
    "        # Figure out what the name should be\n",
    "        \n",
    "        if not replace:\n",
    "            if name == None:\n",
    "                name = clf.__class__.__name__   \n",
    "            elif not isinstance(name,str):\n",
    "                print('Name must be a string!')\n",
    "                return\n",
    "        \n",
    "            if name in self.fits:\n",
    "                i = 1\n",
    "                while name + str(i) in self.fits:\n",
    "                    i += 1\n",
    "            \n",
    "                name = name + str(i)\n",
    "            print('Processing ', end = '')\n",
    "        else:\n",
    "            print('Replacing ', end = '')\n",
    "        print(str(name) + ':', end = '')\n",
    "        #############################################################\n",
    "        \n",
    "        def crossval(clf):        \n",
    "            \n",
    "            probs = np.zeros(shape=(self.N,self.L))\n",
    "            with warnings.catch_warnings(record=True) as warn:\n",
    "                warnings.simplefilter(\"once\")\n",
    "\n",
    "                kf = KFold(n_splits=self.folds)\n",
    "                kf.get_n_splits(self.X)\n",
    "       \n",
    "                for train, test in kf.split(self.X):\n",
    "                    \n",
    "                    if self.M != 2:\n",
    "                        X_train = self.X.iloc[train,:]\n",
    "                        X_test = self.X.iloc[test,:]\n",
    "                    else:\n",
    "                        X_train = self.X.iloc[train]\n",
    "                        X_test = self.X.iloc[test]\n",
    "                    \n",
    "                    y_train = self.y[train]\n",
    "                    \n",
    "                    cbc = CalibratedClassifierCV(clf,cv=2)\n",
    "                    cbc.fit(X_train,y_train)\n",
    "                    probs[test] = cbc.predict_proba(X_test)\n",
    "\n",
    "            return(probs, warn)\n",
    "            #return(1/self.L + np.ones(shape=(sclf.N,self.L+1)),[])\n",
    "\n",
    "        def compute_curves(probs):\n",
    "            res = 200\n",
    "            \n",
    "            points = np.linspace(0,1,num=res)\n",
    "            \n",
    "            @njit\n",
    "            def fast_curve(L,label_bins,probs):\n",
    "                prec = np.zeros(shape=(res,L+1))\n",
    "                recall = np.zeros(shape=(res,L+1))\n",
    "                for i in range(L):\n",
    "                    n_positives = label_bins[:,i].sum()\n",
    "                    for j, k in enumerate(points):\n",
    "                        pred = probs[:,i] >= k\n",
    "                        if pred.sum():\n",
    "                            tp = label_bins[pred,i].sum()\n",
    "                            prec[j,i] = tp/pred.sum()\n",
    "                            recall[j,i] = tp/n_positives\n",
    "                        else:\n",
    "                            prec[j,i] = 1\n",
    "                            recall[j,i] = 0\n",
    "            \n",
    "                for i in range(L):\n",
    "                    for j in range(res):\n",
    "                        prec[j,L] += prec[j,i]/L\n",
    "                        recall[j,L] += recall[j,i]/L\n",
    "                \n",
    "                return(prec,recall)\n",
    "                            \n",
    "            prec, recall = fast_curve(self.L,self.label_bins,probs)   \n",
    "            return({'prec': prec, 'recall': recall})\n",
    "        \n",
    "\n",
    "        def compute_metrics(probs):\n",
    "            pr_vals = np.zeros(shape=(self.folds+1,self.L+1))\n",
    "            kf = KFold(n_splits=self.folds)\n",
    "            kf.get_n_splits(self.X)\n",
    "       \n",
    "            for i in range(self.L):\n",
    "                pr_vals[0,i] = average_precision_score(self.label_bins[:,i],probs[:,i])\n",
    "                for j, (_, test) in enumerate(kf.split(self.X)):\n",
    "                    pr_vals[j+1,i] = average_precision_score(self.label_bins[test,i],\n",
    "                                                             probs[test,i])\n",
    "            \n",
    "                    pr_vals[0,self.L] = average_precision_score(self.label_bins,probs[:,:self.L])\n",
    "                    pr_vals[j+1,self.L] = average_precision_score(self.label_bins[test,:self.L],\n",
    "                                                                  probs[test,:self.L])\n",
    "            pr_mean = pr_vals[0,:]\n",
    "            pr_levelstd = np.std(pr_vals[1:,:],axis=0)\n",
    "            \n",
    "            pr_cvsmean = pr_vals[:,self.L]\n",
    "            pr_cvstd = np.std(pr_vals[:,:self.L],axis=1)\n",
    "\n",
    "    \n",
    "            return({'pr_mean': pr_mean, 'pr_levelstd': pr_levelstd, \n",
    "                    'pr_cvsmean':pr_cvsmean, 'pr_cvstd': pr_cvstd,'pr_table':pr_vals})\n",
    "\n",
    "        try:\n",
    "            with warnings.catch_warnings(record=False):\n",
    "                warnings.simplefilter(\"ignore\")\n",
    "                clf.fit(self.X.iloc[:20,:],self.y.iloc[:20])\n",
    "        except ValueError as val:\n",
    "            print('Fit error: ',end='')\n",
    "            print(val)\n",
    "            return\n",
    "        \n",
    "        ##################################################\n",
    "        \n",
    "        if params != None:\n",
    "            if isinstance(params,dict):\n",
    "                clf.set_params(**params)\n",
    "            else:\n",
    "                print('Params must be a dictionary')\n",
    "\n",
    "        probs, warn = crossval(clf)\n",
    "        curves = compute_curves(probs)\n",
    "        metrics = compute_metrics(probs)\n",
    "        \n",
    "        self.fits[name] = {'clf': clf, 'params': params, 'probs': probs, 'curves': curves, 'metrics': metrics}\n",
    "        \n",
    "        if len(warn) > 0:\n",
    "            print('\\n')\n",
    "            print(warn[0].message)\n",
    "            print('\\n' + 'Added Anyway.' + '\\n')\n",
    "        else:\n",
    "            print(' Added.')\n",
    "        \n",
    "    def remove(self,name=None, keepn=None, by_label = None):\n",
    "        if name == None and keepn==None:\n",
    "            print('Choose a name or the top n to keep.')\n",
    "        elif name != None and keepn != None:\n",
    "            print('Choose a name to remove or the top n to keep!')\n",
    "        elif name != None:\n",
    "            if isinstance(name,str):\n",
    "                if name in self.fits:\n",
    "                    del self.fits[name]\n",
    "                    print(name + ' deleted.')\n",
    "                else:\n",
    "                    print('Key ' + name + ' not in fits.')\n",
    "            else:\n",
    "                print('Name must be a string!')\n",
    "        else:\n",
    "            if by_label == None:\n",
    "                label_position = self.label_position\n",
    "            elif by_label == 'average':\n",
    "                label_position = self.L\n",
    "            elif by_label in self.C:\n",
    "                label_position = np.where(self.C == label)[0][0]\n",
    "            else:\n",
    "                print('Label is not in y!')\n",
    "                return\n",
    "        \n",
    "        \n",
    "            metrics = []\n",
    "            for i in self.fits:\n",
    "                metrics.append([i,self.fits[i]['metrics']['pr_mean'][label_position]])\n",
    "        \n",
    "            metrics.sort(reverse=True,key=lambda x: x[1])\n",
    "            if keepn >= 1:\n",
    "                for i, _ in metrics[int(keepn):]:\n",
    "                    del self.fits[i]\n",
    "                    print('Deleted ' + i + '.')\n",
    "            else:\n",
    "                print('keepn must be greater than one!')\n",
    "            return                                \n",
    "   \n",
    "    def list_fits(self):\n",
    "        for i in self.fits:\n",
    "            print(i)\n",
    "    \n",
    "    def compare(self, label=None, topn = -1):\n",
    "        \"\"\"\n",
    "        This function compares all the fits stored using average precision (AP).\n",
    "        \n",
    "        label : The label specified when self.data() was called, defaulted to 'average' if 'None',\n",
    "        or whatever label you want.\n",
    "        \n",
    "        topn : list only the top n fits as given by average precision. -1 means all fits.\n",
    "        \"\"\"\n",
    "        \n",
    "        \n",
    "        \n",
    "        import matplotlib.pyplot as plt\n",
    "        from tabulate import tabulate\n",
    "        \n",
    "        if not self.data_valid:\n",
    "            print('Data is not valid!')\n",
    "            return\n",
    "        \n",
    "        if label == None:\n",
    "            label = self.label\n",
    "            label_position = self.label_position\n",
    "        elif label in self.C:\n",
    "            label_position = np.where(self.C == label)[0][0]\n",
    "        elif label == 'average':\n",
    "            label = 'Averaged'\n",
    "            label_position = self.L\n",
    "        else:\n",
    "            print('Label is not in y!')\n",
    "            return\n",
    "        \n",
    "      \n",
    "        if label == 'Averaged':\n",
    "            print('\\nAP is averaged across all levels and cross validation subsets. \\n')\n",
    "        else:\n",
    "            print('\\nPositive label is ' + label + '\\n')\n",
    "        \n",
    "        priorp= self.priors[label_position]\n",
    "        \n",
    "        if label == 'Averaged':\n",
    "            headers = ['Model Name','E(AP)','SD(AP|Average Level)','SD(AP|Average Validation)']\n",
    "            metrics = []\n",
    "            for i in self.fits:\n",
    "                metrics.append([i,self.fits[i]['metrics']['pr_mean'][label_position],\n",
    "                                  self.fits[i]['metrics']['pr_levelstd'][label_position],\n",
    "                                  self.fits[i]['metrics']['pr_cvstd'][label_position]])\n",
    "        else:\n",
    "            headers = ['Model Name','E(AP)','SD(AP|level=' + label + ')']\n",
    "            metrics = []\n",
    "            for i in self.fits:\n",
    "                metrics.append([i,self.fits[i]['metrics']['pr_mean'][label_position],\n",
    "                                  self.fits[i]['metrics']['pr_levelstd'][label_position]])\n",
    "        \n",
    "        metrics.sort(reverse=True, key=lambda x: x[1])\n",
    "        if topn >= 1:\n",
    "            metrics1 = metrics[:int(topn)]\n",
    "            metrics2 = metrics1.copy()\n",
    "        else:\n",
    "            metrics1 = metrics\n",
    "            metrics2 = metrics1.copy()\n",
    "            \n",
    "        metrics2.append(['prior only',priorp])\n",
    "        metrics2.append(['perfect',1])\n",
    "        \n",
    "        metrics2.sort(reverse=True, key=lambda x: x[1])\n",
    "        \n",
    "        print(tabulate(metrics2,headers=headers))\n",
    "        \n",
    "        for name in [i[0] for i in metrics1]:\n",
    "            x = self.fits[name]['curves']['recall'][:,label_position]\n",
    "            y = self.fits[name]['curves']['prec'][:,label_position]\n",
    "            plt.plot(x,y,label=name)\n",
    "\n",
    "        plt.title(label + ' Precision Recall Curve')\n",
    "        plt.legend(bbox_to_anchor=(1.04,.5), loc='center left')\n",
    "        plt.xlabel('Recall')\n",
    "        plt.ylabel('Precision')\n",
    "        plt.show()\n",
    "          \n",
    "    def inspect(self,name):\n",
    "        \n",
    "        if name not in self.fits:\n",
    "            print('Your model does not exist!')\n",
    "            return        \n",
    "        \n",
    "        headers = ['Level Name','E(AP|Level)','SD(AP|Level)','E(AP|Prior Only)']\n",
    "        metrics = []\n",
    "        for i, j in enumerate(self.C):\n",
    "            metrics.append([j,self.fits[name]['metrics']['pr_mean'][i],\n",
    "                              self.fits[name]['metrics']['pr_levelstd'][i],self.priors[i]])\n",
    "        \n",
    "        metrics.append(['Averaged',self.fits[name]['metrics']['pr_mean'][self.L],\n",
    "                                   self.fits[name]['metrics']['pr_levelstd'][self.L],self.priors[self.L]])\n",
    "            \n",
    "        print(tabulate(metrics,headers=headers),end='\\n\\n')\n",
    "        \n",
    "        headers = ['Cross Validation','E(AP|Cross Validation)','SD(AP|Cross Validation)']\n",
    "        cvs = []\n",
    "        for i in range(self.folds):\n",
    "            cvs.append([i,self.fits[name]['metrics']['pr_cvsmean'][i],\n",
    "                              self.fits[name]['metrics']['pr_cvstd'][i]])\n",
    "        \n",
    "        cvs.append(['Averaged',self.fits[name]['metrics']['pr_cvsmean'][self.folds],\n",
    "                                   self.fits[name]['metrics']['pr_cvstd'][self.folds]])\n",
    "        \n",
    "        print(tabulate(cvs,headers=headers),end='\\n\\n')\n",
    "        \n",
    "        params = self.fits[name]['params']\n",
    "        if  params != None:\n",
    "            headers = ['Param name','Value']\n",
    "            pp = []\n",
    "            for i in self.fits[name]['params']:\n",
    "                pp.append([i,self.fits[name]['params'][i]])\n",
    "        \n",
    "            print(tabulate(pp,headers=headers),end='\\n\\n')\n",
    "        \n",
    "        for i in range(self.L):\n",
    "                plt.plot(self.fits[name]['curves']['recall'][:,i], \n",
    "                         self.fits[name]['curves']['prec'][:,i],label=self.C[i])\n",
    "\n",
    "        plt.plot(self.fits[name]['curves']['recall'][:,self.L],\n",
    "                     self.fits[name]['curves']['prec'][:,self.L],label='Averaged')\n",
    "        \n",
    "        plt.title(' Precision Recall Curve')\n",
    "        plt.legend(bbox_to_anchor=(1.04,.5), loc='center left')\n",
    "        plt.xlabel('Recall')\n",
    "        plt.ylabel('Precision')\n",
    "        plt.show()\n",
    "        \n",
    "    def suite(self, max_iter = 100000):\n",
    "        \"\"\"\n",
    "        This adds a suite of classifiers at their default values, excpet for a raised max_iter.\n",
    "        \n",
    "        max_iter: the number of iterations before timeout.\n",
    "        \n",
    "        The classifiers added are:\n",
    "        \n",
    "        GaussianNB\n",
    "        LinearSVC\n",
    "        SVC\n",
    "        DecisionTreeClassifier\n",
    "        ExtraTreeClassifier\n",
    "        AdaBoostClassifier\n",
    "        BaggingClassifier\n",
    "        RandomForestClassifier\n",
    "        GradientBoostingClassifier\n",
    "        LogisticRegression\n",
    "        PassiveAggressiveClassifier\n",
    "        Perceptron\n",
    "        RidgeClassifier\n",
    "        SGDClassifier\n",
    "        MLPClassifier\n",
    "        KNeighborsClassifier\n",
    "        \"\"\"\n",
    "        \n",
    "        \n",
    "        print('Adding a suite of classifiers with default parameters.\\n')\n",
    "        self.add_fit(GaussianNB())\n",
    "        \n",
    "        self.add_fit(LinearSVC(max_iter= max_iter))\n",
    "        self.add_fit(SVC())\n",
    "        \n",
    "        self.add_fit(DecisionTreeClassifier())\n",
    "        self.add_fit(ExtraTreeClassifier())\n",
    "        \n",
    "        self.add_fit(AdaBoostClassifier())\n",
    "        self.add_fit(BaggingClassifier())\n",
    "        self.add_fit(RandomForestClassifier())\n",
    "        self.add_fit(GradientBoostingClassifier())\n",
    "       \n",
    "        self.add_fit(LogisticRegression(max_iter=max_iter))\n",
    "        self.add_fit(PassiveAggressiveClassifier(max_iter=max_iter))\n",
    "        self.add_fit(Perceptron(max_iter=max_iter))\n",
    "        self.add_fit(RidgeClassifier(max_iter=max_iter))\n",
    "        self.add_fit(SGDClassifier(max_iter=max_iter))\n",
    "        \n",
    "        self.add_fit(MLPClassifier(max_iter= max_iter))\n",
    "        self.add_fit(KNeighborsClassifier())\n",
    "        print('\\nFinished Adding Classifiers\\n')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
